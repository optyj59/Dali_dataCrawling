📝 유튜브 댓글 DWH 구축 프로젝트 상세 보고서I. 프로젝트 개요 및 목표1. 프로젝트 목표 및 역할본 프로젝트는 유튜브 API를 사용하지 않고 웹 크롤링을 통해 데이터를 수집하여, 시점별 이력 추적(Temporal Data)이 가능한 데이터웨어하우스(DWH)를 구축하고, 이를 기반으로 API 서비스를 개발하는 것을 목표로 합니다.2. 핵심 목표속도 문제 해결: 이전 프로젝트의 실패 원인이었던 동적 콘텐츠(JavaScript) 처리 및 크롤링 속도 문제를 최신 기술 스택으로 해결하는 것입니다.데이터 이력 관리 (SCD Type 2): 댓글 내용 수정/삭제, 영상 및 채널 정보 변경 이력을 완벽하게 보존하는 DWH를 구축합니다.컴플라이언스: PII(개인 식별 정보) 비식별화 처리를 자동화합니다.II. 기술 스택 최종 결정 및 근거역할채택 기술선택 근거 (논리)렌더링/제어Playwright속도 문제 해결 최적화. Selenium 대비 더 빠르고 안정적인 아키텍처를 가졌으며, 서버의 멀티 코어 CPU를 활용한 병렬 처리에 유리합니다. 동적 콘텐츠 로딩과 스크롤 처리에 가장 효율적입니다.HTML 파싱Beautiful Soup (BS4)고속 파싱 및 코드 가독성. Playwright가 렌더링을 완료한 후, HTML 텍스트를 받아 데이터 추출만 빠르게 처리하여 전체 크롤링 속도를 높입니다.데이터베이스 (DB)PostgreSQL이력 관리(SCD Type 2) 및 복잡한 관계형 데이터 처리에 유리합니다. SSD 성능을 활용하여 안정적인 쓰기(Write) 및 조회(Read) 성능을 제공합니다.DB 통신psycopg2Python 환경에서 PostgreSQL DB와 통신하는 데 가장 안정적이고 성능이 우수한 공식 라이브러리입니다.스케줄링Cron서버의 기본 스케줄러로, 매일 새벽 시간대에 크롤링 작업을 자동화 및 주기화하는 데 사용됩니다.III. 데이터 모델링 및 이력 관리 전략1. 데이터베이스 구조 (6개 테이블, 하이브리드 SCD 모델)테이블 명주요 역할이력 관리 전략KEYWORD_MASTER키워드 상태 관리last_used_time을 활용하여 새로운/기존 키워드를 판단하여 DB 검색 부하를 줄입니다.VIDEO_MASTER영상의 고유 정보 (변하지 않는 정보) 저장영상의 고유 식별자(video_id)를 단 1회 저장하여 중복을 방지합니다.KEYWORD_VIDEO_MAPPING필수 이력 테이블특정 시점에 어떤 키워드로 영상이 수집되었는지 기록하여, 과거 시점 조회를 보장합니다.VIDEO_METADATA_HISTORY영상 메타데이터 (조회수, 구독자 수)SCD Type 2 적용. 변경 시 valid_to_time 마감 및 새 레코드 삽입.COMMENT_MASTER댓글 내용 및 본질적 이력SCD Type 2 (선택적). 댓글 내용(content) 변경 및 삭제 시에만 이력을 기록하여 DB 부하를 줄입니다. (like_count 제외)COMMENT_ACTIVITY_LOG좋아요/싫어요 수 기록하이브리드 분리 전략. 잦은 변동 정보만 분리하여 경량 스냅샷 형태로 collection_time을 기준으로 기록합니다.2. PII 비식별화 전략사용자명: user_name 대신 user_alias_id (가명 ID)를 생성하여 저장합니다.댓글 내용 (content): PII 패턴(전화번호, 이메일 등)을 **정규 표현식(Regex)**으로 탐지하여 자동 마스킹 처리합니다.IV. 크롤링 및 DB 저장 상세 파이프라인데이터 수집 및 저장은 4단계의 핵심 과정으로 압축하여 진행되며, SCD 로직은 DB 전송 단계에서 수행됩니다.1. 키워드 상태 확인 (DB 읽기 및 갱신)활동: KEYWORD_MASTER를 참조하여 키워드 상태를 확인하고 (원칙 1/2), 작업 후 last_used_time을 갱신합니다.2. 데이터 크롤링 및 추출활동: Playwright로 유튜브를 검색하고 필터링합니다. 필터를 통과한 영상 페이지에 진입하여 댓글을 로드합니다.추출: 로드된 HTML을 Beautiful Soup으로 넘겨 데이터를 추출하고, PII 마스킹을 수행합니다.3. 크롤링 결과 처리 (메모리 변환)활동: 수집된 데이터를 메모리 상에서 DB 스키마에 맞게 구조화합니다.검증: 결측 데이터는 [NOT NULL] 제약 조건에 따라 폐기하고, 중복 작업 여부를 체크합니다.4. DB 전송 및 이력 기록 (PostgreSQL Write)활동: psycopg2를 사용하여 쿼리를 실행합니다.이력 기록: KEYWORD_VIDEO_MAPPING에 수집 이력을 기록합니다.SCD 갱신: VIDEO_METADATA_HISTORY와 COMMENT_MASTER는 SCD Type 2 로직을 따라 기존 레코드를 마감하고 새 레코드를 삽입합니다.부하 분산: 좋아요/싫어요 수는 COMMENT_ACTIVITY_LOG에만 INSERT하여 COMMENT_MASTER의 쓰기 부하를 방지합니다.V. 제출 산출물 및 관리 구조1. 제출 산출물 포함 사항데이터 스키마(초안): 6개 테이블의 DB Diagram 구조 (PostgreSQL).샘플 데이터: SCD Type 2 이력과 PII 비식별화가 반영된 40건의 CSV 파일 (comment_history_view.csv).전략 문서: 본 보고서의 PPT 버전.2. 폴더 구조youtube_crawler/
├── data/
│   ├── raw/
│   └── processed/      # (샘플 CSV 저장 위치)
├── logs/
│   └── crawler.log
├── src/
│   ├── config.py
│   ├── db_manager.py   # SCD Type 2 로직 핵심
│   ├── crawler_engine.py # Playwright + BS4 로직 핵심
│   └── utils.py
└── main.py